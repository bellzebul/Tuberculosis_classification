{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a0cb09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T11:18:13.599404Z",
     "start_time": "2023-05-29T11:18:11.519198Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact\n",
    "from collections import OrderedDict\n",
    "\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    LoadImage,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    Rotate90d,\n",
    "    apply_transforms\n",
    ")\n",
    "from monai.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b935fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T11:18:13.605953Z",
     "start_time": "2023-05-29T11:18:13.600503Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a47a7cbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:26:25.200563Z",
     "start_time": "2023-05-04T13:26:25.180851Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_path = 'config.yaml'\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b74e197e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:26:26.075115Z",
     "start_time": "2023-05-04T13:26:26.059349Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_directory, masks_directory, transform = None):\n",
    "        self.images_directory = sorted(glob(images_directory + '/*'))\n",
    "        self.masks_directory = sorted(glob(masks_directory + '/*'))\n",
    "        self.img_size = 512\n",
    "        self.lung_2d, self.mask_2d = self.get_lists()\n",
    "\n",
    "        \n",
    "    def get_lists(self):\n",
    "        lung_2d = []\n",
    "        mask_2d = []\n",
    "\n",
    "        for i in range(len(self.images_directory)):\n",
    "\n",
    "            lung_3d = LoadImage(image_only=True, ensure_channel_first=False, simple_keys=True)(self.images_directory[i])\n",
    "            mask_3d = LoadImage(image_only=True, ensure_channel_first=False, simple_keys=True)(self.masks_directory[i])\n",
    "\n",
    "            for j in (pbar := tqdm(range(lung_3d.shape[2]))):\n",
    "                lung_2d.append(lung_3d[:,:,j])\n",
    "                mask_2d.append(mask_3d[:,:,j])\n",
    "\n",
    "        return lung_2d, mask_2d\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.lung_2d)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        \n",
    "        return {'image': self.lung_2d[idx], 'label': self.mask_2d[idx]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "133980c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:26:49.501352Z",
     "start_time": "2023-05-04T13:26:26.915095Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 301/301 [00:00<00:00, 20394.58it/s]\n",
      "100%|██████████████████████████████████████| 200/200 [00:00<00:00, 29836.77it/s]\n",
      "100%|██████████████████████████████████████| 200/200 [00:00<00:00, 13189.22it/s]\n",
      "100%|██████████████████████████████████████| 270/270 [00:00<00:00, 23306.00it/s]\n",
      "100%|████████████████████████████████████████| 290/290 [00:00<00:00, 301.96it/s]\n",
      "100%|██████████████████████████████████████| 213/213 [00:00<00:00, 26000.78it/s]\n",
      "100%|██████████████████████████████████████| 249/249 [00:00<00:00, 13683.71it/s]\n",
      "100%|██████████████████████████████████████| 301/301 [00:00<00:00, 17248.25it/s]\n",
      "100%|██████████████████████████████████████| 256/256 [00:00<00:00, 34721.96it/s]\n",
      "100%|██████████████████████████████████████| 301/301 [00:00<00:00, 13020.28it/s]\n",
      "100%|████████████████████████████████████████| 39/39 [00:00<00:00, 28612.53it/s]\n",
      "100%|██████████████████████████████████████| 418/418 [00:00<00:00, 28540.11it/s]\n",
      "100%|██████████████████████████████████████| 110/110 [00:00<00:00, 33733.53it/s]\n",
      "100%|████████████████████████████████████████| 66/66 [00:00<00:00, 28532.68it/s]\n",
      "100%|████████████████████████████████████████| 42/42 [00:00<00:00, 27197.90it/s]\n",
      "100%|████████████████████████████████████████| 42/42 [00:00<00:00, 32382.49it/s]\n",
      "100%|████████████████████████████████████████| 45/45 [00:00<00:00, 14955.92it/s]\n",
      "100%|████████████████████████████████████████| 93/93 [00:00<00:00, 30519.54it/s]\n",
      "100%|████████████████████████████████████████| 39/39 [00:00<00:00, 32206.71it/s]\n",
      "100%|█████████████████████████████████████████| 45/45 [00:00<00:00, 1119.52it/s]\n"
     ]
    }
   ],
   "source": [
    "params = config['augmentation_staff']\n",
    "lungs_path = os.path.join(params['dataset_path'], 'ct_scans_tr')\n",
    "masks_path = os.path.join(params['dataset_path'], 'lung_mask')\n",
    "train_dataset = MyDataset(lungs_path, masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4823a636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:28:01.272386Z",
     "start_time": "2023-05-04T13:28:00.826136Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc518957b624d008fc80ee145cbd40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1759, description='layer', max=3519), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_layer(layer)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms_for_ploting  = Compose(\n",
    "        [\n",
    "            AddChanneld(keys=[\"image\", \"label\"]),\n",
    "            Rotate90d(keys=[\"image\", \"label\"], k=1, ),\n",
    "            Spacingd(keys=['image', 'label'], pixdim=eval(params['pixdim']), mode=('bilinear', 'nearest')),\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=params['window_lvl'] - params['window_width']/2,\n",
    "                                 a_max=params['window_lvl'] + params['window_width']/2,\n",
    "                                 b_min=0.0, b_max=1.0, clip=True), \n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),    \n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size = eval(params['img_size'])),\n",
    "        ]\n",
    "        )\n",
    "def show_layer(layer):\n",
    "    patient = train_dataset[layer]\n",
    "    patient = transforms_for_ploting(patient)\n",
    "    lung = patient['image'].squeeze()\n",
    "    mask = patient['label'].squeeze()\n",
    "    fig = plt.figure(figsize=(18, 15))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(lung, cmap='bone')\n",
    "    plt.axis('off')\n",
    "    plt.title('Original')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(lung, cmap='bone')\n",
    "    plt.imshow(mask,  alpha = 0.5,cmap='nipy_spectral')\n",
    "    plt.axis('off')\n",
    "    plt.title('With mask')\n",
    "\n",
    "interact(show_layer, layer=(0, len(train_dataset)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "03842433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:28:04.614945Z",
     "start_time": "2023-05-04T13:28:04.590815Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "        [\n",
    "            AddChanneld(keys=[\"image\", \"label\"]),\n",
    "            Rotate90d(keys=[\"image\", \"label\"], k=1),\n",
    "            Spacingd(keys=['image', 'label'], pixdim=eval(params['pixdim']), mode=('bilinear', 'nearest')),\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=params['window_lvl'] - params['window_width']/2,\n",
    "                                 a_max=params['window_lvl'] + params['window_width']/2,\n",
    "                                 b_min=0.0, b_max=1.0, clip=True), \n",
    "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),    \n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size = eval(params['img_size'])),\n",
    "            ToTensord(keys=[\"image\", \"label\"]),\n",
    "\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "95e66a3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:28:07.063165Z",
     "start_time": "2023-05-04T13:28:07.041172Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_for_dataloader = [patient for patient in train_dataset]\n",
    "transformed_dataset = Dataset(data=train_dataset_for_dataloader, transform=train_transforms)\n",
    "train_loader = DataLoader(transformed_dataset, num_workers = 1, batch_size=params['batch_size'], shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "feeae427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:28:08.299634Z",
     "start_time": "2023-05-04T13:28:08.290144Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = 1.0\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        y_pred = y_pred[:, 0].contiguous().view(-1)\n",
    "        y_true = y_true[:, 0].contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dsc = (2. * intersection + self.smooth) / (\n",
    "            y_pred.sum() + y_true.sum() + self.smooth\n",
    "        )\n",
    "        return 1. - dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "39ede137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:28:20.104224Z",
     "start_time": "2023-05-04T13:28:15.295944Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_train = config['train_staff']\n",
    "if params_train['device'] == 'mps':\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "elif params_train['device'] == 'cuda':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet()\n",
    "model.to(device)\n",
    "dc_loss = DiceLoss()\n",
    "dc_loss = dc_loss.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas = (0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9495ad15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:28:22.402423Z",
     "start_time": "2023-05-04T13:28:22.396653Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1671b881",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T13:28:22.665127Z",
     "start_time": "2023-05-04T13:28:22.653971Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7762465"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8a2f426f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T11:14:42.099106Z",
     "start_time": "2023-05-04T11:14:37.745284Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/38 [00:00<?, ?it/s]/Users/bellzebull/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/monai/data/__init__.py:120: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n",
      "/Users/bellzebull/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torch/_tensor.py:1295: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ret = func(*args, **kwargs)\n",
      "/Users/bellzebull/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/monai/data/__init__.py:127: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if storage.is_cuda:\n",
      "  0%|                                                    | 0/38 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 7.51 GB, other allocations: 1.80 GB, max allowed: 9.07 GB). Tried to allocate 256 bytes on shared pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlung\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m dc_loss(pred, label)\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[43], line 40\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 40\u001b[0m     enc1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     enc2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(enc1))\n\u001b[1;32m     42\u001b[0m     enc3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(enc2))\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:151\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[1;32m    153\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 7.51 GB, other allocations: 1.80 GB, max allowed: 9.07 GB). Tried to allocate 256 bytes on shared pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "epochs = params_train['networks']['epochs']\n",
    "loss_epochs_list = []\n",
    "acc_epochs_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    loop = tqdm(train_loader)\n",
    "    for sample in loop:\n",
    "        lung, label = sample['image'], sample['label']\n",
    "        lung = lung.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(lung)\n",
    "        \n",
    "        loss = dc_loss(pred, label)\n",
    "        loss.backward()\n",
    "        loss_val += loss.item()\n",
    "        \n",
    "        acc_current = 1 - dc_loss(pred.cpu().float(), label.cpu().float())\n",
    "        acc_val += acc_current\n",
    "        optimizer.step()\n",
    "        loop.set_description_str(f'loss = {loss.item()}   acc = {acc_current}')\n",
    "        \n",
    "    scheduler.step()\n",
    "    torch.save(model.state_dict(), 'model_weights')\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
